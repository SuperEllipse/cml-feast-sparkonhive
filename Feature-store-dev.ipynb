{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9588de38-9414-483f-880f-a8395e39451b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdsw/.local/lib/python3.9/site-packages/feast/infra/offline_stores/contrib/spark_offline_store/spark_source.py:67: RuntimeWarning: The spark data source API is an experimental feature in alpha development. This API is unstable and it could and most probably will be changed in the future.\n",
      "  warnings.warn(\n",
      "/home/cdsw/.local/lib/python3.9/site-packages/feast/infra/offline_stores/contrib/spark_offline_store/spark.py:137: RuntimeWarning: The spark offline store is an experimental feature in alpha development. Some functionality may still be unstable so functionality can change in the future.\n",
      "  warnings.warn(\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "/home/cdsw/.local/lib/python3.9/site-packages/pyspark/sql/pandas/conversion.py:371: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "24/02/23 05:35:43 WARN HiveClientImpl: Detected HiveConf hive.execution.engine is 'tez' and will be reset to 'mr' to disable useless hive logic\n",
      "Hive Session ID = 18ae1d4c-cb5b-455b-89fa-3315b90909c3\n",
      "24/02/23 05:35:45 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "[Stage 11:=========================================>            (154 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Feature schema -----\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 8 columns):\n",
      " #   Column                              Non-Null Count  Dtype         \n",
      "---  ------                              --------------  -----         \n",
      " 0   driver_id                           3 non-null      int64         \n",
      " 1   event_timestamp                     3 non-null      datetime64[ns]\n",
      " 2   label_driver_reported_satisfaction  3 non-null      int64         \n",
      " 3   val_to_add                          3 non-null      int64         \n",
      " 4   val_to_add_2                        3 non-null      int64         \n",
      " 5   conv_rate                           3 non-null      float32       \n",
      " 6   conv_rate_plus_val1                 3 non-null      float64       \n",
      " 7   conv_rate_plus_val2                 3 non-null      float64       \n",
      "dtypes: datetime64[ns](1), float32(1), float64(2), int64(4)\n",
      "memory usage: 308.0 bytes\n",
      "None\n",
      "\n",
      "----- Example features -----\n",
      "\n",
      "   driver_id            event_timestamp  label_driver_reported_satisfaction  \\\n",
      "0       1003 2024-02-23 05:35:37.204273                                   3   \n",
      "1       1001 2024-02-23 05:35:37.204273                                   1   \n",
      "2       1002 2024-02-23 05:35:37.204273                                   5   \n",
      "\n",
      "   val_to_add  val_to_add_2  conv_rate  conv_rate_plus_val1  \\\n",
      "0           3            30   0.745193             3.745193   \n",
      "1           1            10   0.812710             1.812710   \n",
      "2           2            20   0.131389             2.131389   \n",
      "\n",
      "   conv_rate_plus_val2  \n",
      "0            30.745193  \n",
      "1            10.812710  \n",
      "2            20.131389  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdsw/.local/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])\n",
      "/home/cdsw/.local/lib/python3.9/site-packages/pyspark/sql/pandas/conversion.py:194: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n",
      "/home/cdsw/.local/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from feast import FeatureStore\n",
    "\n",
    "# Note: see https://docs.feast.dev/getting-started/concepts/feature-retrieval for \n",
    "# more details on how to retrieve for all entities in the offline store instead\n",
    "entity_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        # entity's join key -> entity values\n",
    "        \"driver_id\": [1001, 1002, 1003],\n",
    "        # \"event_timestamp\" (reserved key) -> timestamps\n",
    "        \"event_timestamp\": [\n",
    "            datetime(2023, 4, 12, 10, 59, 42),\n",
    "            datetime(2023, 4, 12, 8, 12, 10),\n",
    "            datetime(2023, 4, 12, 16, 40, 26),\n",
    "        ],\n",
    "        # (optional) label name -> label values. Feast does not process these\n",
    "        \"label_driver_reported_satisfaction\": [1, 5, 3],\n",
    "        \"val_to_add\": [1, 2, 3],\n",
    "        \"val_to_add_2\": [10, 20, 30],\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "store = FeatureStore(repo_path=\"./feast_project/feature_repo\")\n",
    "entity_df[\"event_timestamp\"] = pd.to_datetime(\"now\", utc=True)\n",
    "feature_service = store.get_feature_service(\"driver_activity_v1\")\n",
    "\n",
    "\n",
    "training_df = store.get_historical_features(\n",
    "    entity_df=entity_df,features=feature_service,\n",
    "    # features=[\n",
    "    #     \"driver_hourly_stats:conv_rate\",\n",
    "    #     \"driver_hourly_stats:acc_rate\",\n",
    "    #     \"driver_hourly_stats:avg_daily_trips\",\n",
    "    # ],\n",
    ").to_df()\n",
    "\n",
    "print(\"----- Feature schema -----\\n\")\n",
    "print(training_df.info())\n",
    "\n",
    "print()\n",
    "print(\"----- Example features -----\\n\")\n",
    "print(training_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ccae1c3-f47d-4d3d-9d4a-5e46edaeadf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_id</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>label_driver_reported_satisfaction</th>\n",
       "      <th>val_to_add</th>\n",
       "      <th>val_to_add_2</th>\n",
       "      <th>conv_rate</th>\n",
       "      <th>conv_rate_plus_val1</th>\n",
       "      <th>conv_rate_plus_val2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1003</td>\n",
       "      <td>2024-02-23 05:35:37.204273</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.745193</td>\n",
       "      <td>3.745193</td>\n",
       "      <td>30.745193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>2024-02-23 05:35:37.204273</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.812710</td>\n",
       "      <td>1.812710</td>\n",
       "      <td>10.812710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>2024-02-23 05:35:37.204273</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.131389</td>\n",
       "      <td>2.131389</td>\n",
       "      <td>20.131389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   driver_id            event_timestamp  label_driver_reported_satisfaction  \\\n",
       "0       1003 2024-02-23 05:35:37.204273                                   3   \n",
       "1       1001 2024-02-23 05:35:37.204273                                   1   \n",
       "2       1002 2024-02-23 05:35:37.204273                                   5   \n",
       "\n",
       "   val_to_add  val_to_add_2  conv_rate  conv_rate_plus_val1  \\\n",
       "0           3            30   0.745193             3.745193   \n",
       "1           1            10   0.812710             1.812710   \n",
       "2           2            20   0.131389             2.131389   \n",
       "\n",
       "   conv_rate_plus_val2  \n",
       "0            30.745193  \n",
       "1            10.812710  \n",
       "2            20.131389  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eb26434-9270-448c-9d7d-2e387db1c1b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdsw/.local/lib/python3.9/site-packages/feast/infra/offline_stores/contrib/spark_offline_store/spark_source.py:67: RuntimeWarning: The spark data source API is an experimental feature in alpha development. This API is unstable and it could and most probably will be changed in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Materializing \u001b[1m\u001b[32m2\u001b[0m feature views to \u001b[1m\u001b[32m2024-02-23 05:37:02+00:00\u001b[0m into the \u001b[1m\u001b[32msqlite\u001b[0m online store.\n",
      "\n",
      "\u001b[1m\u001b[32mdriver_hourly_stats_fresh\u001b[0m from \u001b[1m\u001b[32m2022-10-11 05:37:09+00:00\u001b[0m to \u001b[1m\u001b[32m2024-02-23 05:37:02+00:00\u001b[0m:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/23/2024 05:37:09 AM urllib3.connection WARNING: Certificate did not match expected hostname: usage.feast.dev. Certificate: {'subject': ((('countryName', 'US'),), (('stateOrProvinceName', 'California'),), (('localityName', 'San Francisco'),), (('organizationName', 'Netlify, Inc'),), (('commonName', '*.netlify.app'),)), 'issuer': ((('countryName', 'US'),), (('organizationName', 'DigiCert Inc'),), (('commonName', 'DigiCert Global G2 TLS RSA SHA256 2020 CA1'),)), 'version': 3, 'serialNumber': '03ED167A2659DA278E7B21CDBEB33E32', 'notBefore': 'Jan 15 00:00:00 2024 GMT', 'notAfter': 'Feb 14 23:59:59 2025 GMT', 'subjectAltName': (('DNS', '*.netlify.app'), ('DNS', 'netlify.app')), 'OCSP': ('http://ocsp.digicert.com',), 'caIssuers': ('http://cacerts.digicert.com/DigiCertGlobalG2TLSRSASHA2562020CA1-1.crt',), 'crlDistributionPoints': ('http://crl3.digicert.com/DigiCertGlobalG2TLSRSASHA2562020CA1-1.crl', 'http://crl4.digicert.com/DigiCertGlobalG2TLSRSASHA2562020CA1-1.crl')}\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "/home/cdsw/.local/lib/python3.9/site-packages/feast/infra/offline_stores/contrib/spark_offline_store/spark.py:78: RuntimeWarning: The spark offline store is an experimental feature in alpha development. Some functionality may still be unstable so functionality can change in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling latest features from spark offline store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/23 05:37:13 WARN HiveClientImpl: Detected HiveConf hive.execution.engine is 'tez' and will be reset to 'mr' to disable useless hive logic\n",
      "Hive Session ID = 936fbc71-f1da-47dd-a138-f4d1a5019565\n",
      "24/02/23 05:37:21 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "/home/cdsw/.local/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])\n",
      "/home/cdsw/.local/lib/python3.9/site-packages/pyspark/sql/pandas/conversion.py:194: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n",
      "/home/cdsw/.local/lib/python3.9/site-packages/pyspark/sql/pandas/conversion.py:194: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n",
      "100%|█████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 29.85it/s]\n",
      "/home/cdsw/.local/lib/python3.9/site-packages/feast/infra/offline_stores/contrib/spark_offline_store/spark_source.py:67: RuntimeWarning: The spark data source API is an experimental feature in alpha development. This API is unstable and it could and most probably will be changed in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mdriver_hourly_stats\u001b[0m from \u001b[1m\u001b[32m2022-10-11 05:37:29+00:00\u001b[0m to \u001b[1m\u001b[32m2024-02-23 05:37:02+00:00\u001b[0m:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdsw/.local/lib/python3.9/site-packages/feast/infra/offline_stores/contrib/spark_offline_store/spark.py:78: RuntimeWarning: The spark offline store is an experimental feature in alpha development. Some functionality may still be unstable so functionality can change in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling latest features from spark offline store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdsw/.local/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])\n",
      "/home/cdsw/.local/lib/python3.9/site-packages/pyspark/sql/pandas/conversion.py:194: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n",
      "/home/cdsw/.local/lib/python3.9/site-packages/pyspark/sql/pandas/conversion.py:194: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n",
      "100%|█████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 36.02it/s]\n",
      "/home/cdsw/.local/lib/python3.9/site-packages/feast/infra/offline_stores/contrib/spark_offline_store/spark_source.py:67: RuntimeWarning: The spark data source API is an experimental feature in alpha development. This API is unstable and it could and most probably will be changed in the future.\n",
      "  warnings.warn(\n",
      "02/23/2024 05:37:30 AM urllib3.connection WARNING: Certificate did not match expected hostname: usage.feast.dev. Certificate: {'subject': ((('countryName', 'US'),), (('stateOrProvinceName', 'California'),), (('localityName', 'San Francisco'),), (('organizationName', 'Netlify, Inc'),), (('commonName', '*.netlify.app'),)), 'issuer': ((('countryName', 'US'),), (('organizationName', 'DigiCert Inc'),), (('commonName', 'DigiCert Global G2 TLS RSA SHA256 2020 CA1'),)), 'version': 3, 'serialNumber': '03ED167A2659DA278E7B21CDBEB33E32', 'notBefore': 'Jan 15 00:00:00 2024 GMT', 'notAfter': 'Feb 14 23:59:59 2025 GMT', 'subjectAltName': (('DNS', '*.netlify.app'), ('DNS', 'netlify.app')), 'OCSP': ('http://ocsp.digicert.com',), 'caIssuers': ('http://cacerts.digicert.com/DigiCertGlobalG2TLSRSASHA2562020CA1-1.crt',), 'crlDistributionPoints': ('http://crl3.digicert.com/DigiCertGlobalG2TLSRSASHA2562020CA1-1.crl', 'http://crl4.digicert.com/DigiCertGlobalG2TLSRSASHA2562020CA1-1.crl')}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#ingest data into Online store \n",
    "cd feast_project/feature_repo\n",
    "CURRENT_TIME=$(date -u +\"%Y-%m-%dT%H:%M:%S\")\n",
    "feast materialize-incremental $CURRENT_TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1566e2f4-0076-4c0b-80db-0b4deb315e73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc_rate': [0.011025987565517426, 0.3090273141860962],\n",
      " 'avg_daily_trips': [711, 44],\n",
      " 'conv_rate': [0.8127095699310303, 0.13138850033283234],\n",
      " 'driver_id': [1001, 1002]}\n"
     ]
    }
   ],
   "source": [
    "# Fetching Feature vectors for inference\n",
    "from pprint import pprint\n",
    "from feast import FeatureStore\n",
    "\n",
    "store = FeatureStore(repo_path=\"./feast_project/feature_repo\")\n",
    "\n",
    "feature_vector = store.get_online_features(\n",
    "    features=[\n",
    "        \"driver_hourly_stats:conv_rate\",\n",
    "        \"driver_hourly_stats:acc_rate\",\n",
    "        \"driver_hourly_stats:avg_daily_trips\",\n",
    "    ],\n",
    "    entity_rows=[\n",
    "        # {join_key: entity_value}\n",
    "        {\"driver_id\": 1001, \"val_to_add\": 1000, \"val_to_add_2\": 2000,},\n",
    "        {\"driver_id\": 1002, \"val_to_add\": 3000,\"val_to_add_2\": 4000,},\n",
    "    ],\n",
    ").to_dict()\n",
    "\n",
    "pprint(feature_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6d727d0-6353-4199-8510-423d81874059",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_rate': [0.8127095699310303, 0.13138850033283234],\n",
      " 'conv_rate_plus_val1': [1000.812709569931, 3000.131388500333],\n",
      " 'conv_rate_plus_val2': [2000.812709569931, 4000.131388500333],\n",
      " 'driver_id': [1001, 1002]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdsw/.local/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])\n",
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 47618)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/local/lib/python3.9/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/local/lib/python3.9/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/local/lib/python3.9/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/cdsw/.local/lib/python3.9/site-packages/pyspark/accumulators.py\", line 262, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/cdsw/.local/lib/python3.9/site-packages/pyspark/accumulators.py\", line 235, in poll\n",
      "    if func():\n",
      "  File \"/home/cdsw/.local/lib/python3.9/site-packages/pyspark/accumulators.py\", line 239, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/cdsw/.local/lib/python3.9/site-packages/pyspark/serializers.py\", line 564, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#USING FEATURE SERVICE TO FETCH ONLINE FEATURES\n",
    "\n",
    "from pprint import pprint\n",
    "from feast import FeatureStore\n",
    "\n",
    "feature_store = FeatureStore(repo_path=\"./feast_project/feature_repo\")\n",
    "\n",
    "feature_service = feature_store.get_feature_service(\"driver_activity_v1\")\n",
    "feature_vector = feature_store.get_online_features(\n",
    "    features=feature_service,\n",
    "    entity_rows=[\n",
    "        # {join_key: entity_value}\n",
    "        {\"driver_id\": 1001, \"val_to_add\": 1000, \"val_to_add_2\": 2000,},\n",
    "        {\"driver_id\": 1002, \"val_to_add\": 3000,\"val_to_add_2\": 4000,},\n",
    "    ],\n",
    ").to_dict()\n",
    "pprint(feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f902a8b-aa18-4b28-b5c0-8b86c03bb3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Step 4: Step 4: Browse your features with the Web UI (experimental)\n",
    "cd good_mallard\n",
    "feast ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0acbe1-2127-4e01-b17f-8ae3740e2da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
